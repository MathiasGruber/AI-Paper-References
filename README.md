# References
References for papers that I've read so that I can easily find them again. Not exhaustive, but trying to keep it up to date.

# Foundational
**2020**, Knowledge-primed neural networks enable biologically interpretable deep learning on single-cell sequencing data [[paper](https://genomebiology.biomedcentral.com/track/pdf/10.1186/s13059-020-02100-5.pdf)]
* Nikolaus Fortelny and Christoph Bock, Genome Biology (2020) 21:190 

**2020**, Supervised Contrastive Learning, [[paper](https://arxiv.org/abs/2004.11362)]
* Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan, 	arXiv:2004.11362 [cs.LG]

**2020**, fastai: A Layered API for Deep Learning, [[paper](https://arxiv.org/abs/2002.04688)] [[code](https://github.com/fastai/fastai)]
* Jeremy Howard, Sylvain Gugger, 	arXiv:2002.04688 [cs.LG]

**2020**, Shapley Flow: A Graph-based Approach to Interpreting Model Predictions, [[paper](https://arxiv.org/abs/2010.14592)]
* Jiaxuan Wang, Jenna Wiens, Scott Lundberg, arXiv:2010.14592 [cs.LG]

**2020**, When Does Preconditioning Help or Hurt Generalization?, [[paper](https://arxiv.org/abs/2006.10732)]
* Shun-ichi Amari, Jimmy Ba, Roger Grosse, Xuechen Li, Atsushi Nitanda, Taiji Suzuki, Denny Wu, Ji Xu, 	arXiv:2006.10732 [stat.ML]

**2019**, Which principal components are most sensitive to distributional changes?, [[paper](https://arxiv.org/abs/1905.06318)]
* Martin Tveten, arXiv:1905.06318 [math.ST]

**2019**, Adversarial Examples Are Not Bugs, They are Features [[paper](https://arxiv.org/pdf/1905.02175.pdf)]
* Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, Brandon Tran, Aleksander Madry, arXiv:1905.02175 [stat.ML]

**2019**, Learning Loss for Active Learning [[paper](https://arxiv.org/pdf/1905.03677.pdf)]
* Donggeun Yoo, In So Kweon, arXiv:1905.03677 [cs.CV]

**2019**, Class-Balanced Loss Based on Effective Number of Samples [[paper](https://arxiv.org/abs/1901.05555)]
* Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, Serge Belongie, 	arXiv:1901.05555 [cs.CV]

**2019**, Lookahead Optimizer: k steps forward, 1 step back, [[paper](https://arxiv.org/abs/1907.08610v1)]
* Michael R. Zhang, James Lucas, Geoffrey Hinton, Jimmy Ba, arXiv:1907.08610 [cs.LG]

**2019**, Four Things Everyone Should Know to Improve Batch Normalization, [[paper](https://arxiv.org/abs/1906.03548)]
* Cecilia Summers, Michael J. Dinneen, arXiv:1906.03548 [cs.LG]

**2019**, Large Batch Optimization for Deep Learning: Training BERT in 76 minutes [[paper](https://arxiv.org/abs/1904.00962)]
* Yang You, Jing Li, Sashank Reddi, Jonathan Hseu, Sanjiv Kumar, Srinadh Bhojanapalli, Xiaodan Song, James Demmel, Cho-Jui Hsieh, 	arXiv:1904.00962 [cs.LG]

**2019**, Predicting the Generalization Gap in Deep Networks with Margin Distributions [[paper](https://arxiv.org/abs/1810.00113)]
* Yiding Jiang, Dilip Krishnan, Hossein Mobahi, Samy Bengio,	arXiv:1810.00113 [stat.ML]

**2017-2019**, Decoupled Weight Decay Regularization [[paper](https://arxiv.org/abs/1711.05101)]
* Ilya Loshchilov, Frank Hutter, 	arXiv:1711.05101 [cs.LG]

**2018**, Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks [[paper](https://arxiv.org/abs/1806.05393)] [[tensorflow-implementation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/init_ops.py)]
* Lechao Xiao, Yasaman Bahri, Jascha Sohl-Dickstein, Samuel S. Schoenholz, Jeffrey Pennington, 	arXiv:1806.05393 [stat.ML]

**2017**, Self-Normalizing Neural Networks, [[paper](https://arxiv.org/abs/1706.02515)]
* Günter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter, 	arXiv:1706.02515 [cs.LG]

**2016**, All you need is a good init [[paper](https://arxiv.org/abs/1511.06422)] [[unofficial keras-code](https://github.com/ducha-aiki/LSUV-keras)]  [[pytorch-implementation](https://github.com/ducha-aiki/LSUV-pytorch)]
* Dmytro Mishkin, Jiri Matas, arXiv:1511.06422 [cs.LG]

**2009**, Measuring classifier performance: a coherent alternative to the area under the ROC curve, [[paper](https://link.springer.com/article/10.1007/s10994-009-5119-5)]
* David J. Hand, Hand, D.J. Mach Learn (2009) 77: 103.

# Traditional Machine Learning
**2019 (2012)**, High-Dimensional Feature Selection by Feature-Wise Kernelized Lasso [[paper](https://arxiv.org/abs/1202.0515)] [[code](https://github.com/riken-aip/pyHSICLasso)]
* Makoto Yamada, Wittawat Jitkrittum, Leonid Sigal, Eric P. Xing, Masashi Sugiyama, arXiv:1202.0515 [stat.ML]

**2019**, TriMap: Large-scale Dimensionality Reduction Using Triplets, [[paper](https://arxiv.org/abs/1910.00204)] [[code](https://github.com/eamid/trimap)]
* Ehsan Amid, Manfred K. Warmuth, arXiv:1910.00204 [cs.LG]

**2019**, NGBoost: Natural Gradient Boosting for Probabilistic Prediction [[paper](https://arxiv.org/abs/1910.03225)]
* Tony Duan, Anand Avati, Daisy Yi Ding, Sanjay Basu, Andrew Y. Ng, Alejandro Schuler, arXiv:1910.03225 [cs.LG]

**2019**, KTBoost: Combined Kernel and Tree Boosting [[paper](https://arxiv.org/pdf/1902.03999.pdf)] [[code](https://github.com/fabsig/KTBoost)]
* Fabio Sigrist, arXiv:1902.03999 [cs.LG]

# Recommendation Models
**2016**, Deep Neural Networks for YouTube Recommendations, [[paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf)]
* Paul Covington, Jay Adams, Emre Sargin, Proceedings of the 10th ACM Conference on Recommender Systems, ACM, New York, NY, USA

# Probabilistic Models
**2020**, ConBO: Conditional Bayesian Optimization [[paper](https://arxiv.org/abs/2002.09996)]
* Michael Pearce, Janis Klaise, Matthew Groves, 	arXiv:2002.09996 [stat.ML]

**2019**, Learning Hierarchical Priors in VAEs, [[paper](https://arxiv.org/abs/1905.04982)]
* Alexej Klushyn, Nutan Chen, Richard Kurle, Botond Cseke, Patrick van der Smagt, rXiv:1905.04982 [stat.ML]

**2019**, BoTorch: Programmable Bayesian Optimization in PyTorch, [[paper](https://arxiv.org/abs/1910.06403)] [[code](https://github.com/pytorch/botorch)]
* Maximilian Balandat, Brian Karrer, Daniel R. Jiang, Samuel Daulton, Benjamin Letham, Andrew Gordon Wilson, Eytan Bakshy, arXiv:1910.06403 [cs.LG]

**2019**, GPyTorch: Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration, [[paper](https://arxiv.org/abs/1809.11165)] [[code](https://gpytorch.ai/)]
* Jacob R. Gardner, Geoff Pleiss, David Bindel, Kilian Q. Weinberger, Andrew Gordon Wilson, 	arXiv:1809.11165 [cs.LG]

**2018**, Dealing with Categorical and Integer-valued Variables in Bayesian Optimization with Gaussian Processes, [[paper](https://arxiv.org/abs/1805.03463)]
* Eduardo C. Garrido-Merchán, Daniel Hernández-Lobato,	arXiv:1805.03463 [stat.ML]

**2018**, A Tutorial on Bayesian Optimization, [[paper](https://arxiv.org/abs/1807.02811)]
* Peter I. Frazier, arXiv:1807.02811 [stat.ML]

**2018**, Subset-Conditioned Generation Using Variational Autoencoder With A Learnable Tensor-Train Induced Prior, [[paper](http://bayesiandeeplearning.org/2018/papers/55.pdf)]
* Maksim Kuznetsov et al, Third workshop on Bayesian Deep Learning (NeurIPS 2018), Montréal, Canada.

# Semi-Supervised Learning
**2020**, FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence [[paper](https://arxiv.org/abs/2001.07685)]
* Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, Colin Raffel, arXiv:2001.07685 [cs.LG]

**2019**, MixMatch: A Holistic Approach to Semi-Supervised Learning, [[paper](https://arxiv.org/abs/1905.02249)]
* David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, Colin Raffel, arXiv:1905.02249 [cs.LG]

# Image Generation
**2019**, High-Fidelity Image Generation With Fewer Labels, [[paper](https://arxiv.org/abs/1903.02271v1)] [[code](https://github.com/google/compare_gan)]
* Mario Lucic, Michael Tschannen, Marvin Ritter, Xiaohua Zhai, Olivier Bachem, Sylvain Gelly

# Image Inpainting
**2021**, Large Scale Image Completion via Co-Modulated Generative Adversarial Networks, [[paper](https://arxiv.org/abs/2103.10428)] [[code](https://github.com/zsyzzsoft/co-mod-gan)]
* Shengyu Zhao, Jonathan Cui, Yilun Sheng, Yue Dong, Xiao Liang, Eric I Chang, Yan Xu, 	arXiv:2103.10428 [cs.CV]

**2019**, Free-Form Image Inpainting with Gated Convolution, [[paper](https://arxiv.org/abs/1806.03589)]
* Jiahui Yu, Zhe Lin, Jimei Yang, Xiaohui Shen, Xin Lu, Thomas Huang, arXiv:1806.03589 [cs.CV]

**2018**, Image Inpainting for Irregular Holes Using Partial Convolutions, [[paper](https://arxiv.org/abs/1804.07723)] [[code](https://github.com/NVIDIA/partialconv)]
* Guilin Liu, Fitsum A. Reda, Kevin J. Shih, Ting-Chun Wang, Andrew Tao, Bryan Catanzaro, arXiv:1804.07723 [cs.CV]

# Style Transfer
**2021**, DALL·E: Creating Images from Text, [[article](https://openai.com/blog/dall-e/#summary)]
* OpenAI

**2020**, Analyzing and Improving the Image Quality of StyleGAN, [[paper](https://arxiv.org/abs/1912.04958)]
* Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila, arXiv:1912.04958 [cs.CV]

**2019**, TraVeLGAN: Image-to-image Translation by Transformation Vector Learning [[paper](https://arxiv.org/abs/1902.09631)]
* Matthew Amodio, Smita Krishnaswamy, arXiv:1902.09631 [cs.CV]

**2018**, Learning Linear Transformations for Fast Arbitrary Style Transfer [[paper](https://arxiv.org/abs/1808.04537)] [[official pytorch-code](https://github.com/sunshineatnoon/LinearStyleTransfer)]
* Xueting Li, Sifei Liu, Jan Kautz, Ming-Hsuan Yang, arXiv:1808.04537 [cs.CV]

**2017**, Universal Style Transfer via Feature Transforms [[paper](https://arxiv.org/pdf/1705.08086.pdf)]
* Yijun Li, Chen Fang, Jimei Yang, Zhaowen Wang, Xin Lu, Ming-Hsuan Yang, arXiv:1705.08086 [cs.CV]

**2017**, Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization [[paper](https://arxiv.org/abs/1703.06868)] [[official pytorch-code](https://github.com/xunhuang1995/AdaIN-style)]
* Xun Huang, Serge Belongie, arXiv:1703.06868 [cs.CV]

# Image Classification / Object Detection
**2021**, An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale, [[paper](https://openreview.net/forum?id=YicbFdNTTy)]
* Anonymous

**2020**, EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks, [[paper](https://arxiv.org/abs/1905.11946)]
* Mingxing Tan, Quoc V. Le, arXiv:1905.11946 [cs.LG]

**2020**, Label-free Quantification of Pharmacokinetics in Skin with Stimulated Raman Scattering Microscopy and Deep Learning [[paper](https://www.sciencedirect.com/science/article/abs/pii/S0022202X20318844)]
Amin Feizpour, Troels Marstrand, Louise Bastholm, Stefan Eirefelt, Conor L.Evans

**2020**, Dense Steerable Filter CNNs for Exploiting Rotational Symmetry in Histology Images, [[paper](https://arxiv.org/abs/2004.03037)] [[code](https://github.com/simongraham/dsf-cnn)]
* Simon Graham, David Epstein, Nasir Rajpoot, arXiv:2004.03037 [eess.IV]

**2019**, Improving Uncertainty Estimation in Convolutional Neural Networks Using Inter-rater Agreement, [[paper](https://link.springer.com/chapter/10.1007/978-3-030-32251-9_59)]
* Martin Holm Jensen, Dan Richter Jørgensen, Raluca Jalaboi, Mads Eiler Hansen, Martin Aastrup Olsen, MICCAI 2019. MICCAI 2019. Lecture Notes in Computer Science, vol 11767. Springer, Cham

**2019**, Learning Data Augmentation Strategies for Object Detection [[paper](https://arxiv.org/abs/1906.11172v1)] 
[[code](https://github.com/tensorflow/tpu/tree/master/models/official/detection)]
* Barret Zoph, Ekin D. Cubuk, Golnaz Ghiasi, Tsung-Yi Lin, Jonathon Shlens, Quoc V. Le, arXiv:1906.11172 [cs.CV]

**2019**, AutoAugment: Learning Augmentation Policies from Data [[paper](https://arxiv.org/abs/1805.09501)] [[code](https://github.com/tensorflow/models/tree/master/research/autoaugment)] [[bayesian-version in keras](https://github.com/barisozmen/deepaugment)]
* Ekin D. Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V. Le, 	arXiv:1805.09501 [cs.CV]

**2019**, Fast AutoAugment [[paper](https://arxiv.org/abs/1905.00397)] [[official pytorch-code](https://github.com/kakaobrain/fast-autoaugment)]
* Sungbin Lim, Ildoo Kim, Taesup Kim, Chiheon Kim, Sungwoong Kim, arXiv:1905.00397 [cs.LG]

**2018**, Bag of Tricks for Image Classification with Convolutional Neural Networks [[paper](https://arxiv.org/abs/1812.01187)]
* Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, Mu Li, arXiv:1812.01187 [cs.CV]

# Sequence Models
**2019**, Legendre Memory Units: Continuous-Time Representation in Recurrent Neural Networks, [[paper](http://compneuro.uwaterloo.ca/files/publications/voelker.2019.lmu.pdf)]
* Voelker, Aaron and Kaji, Ivana and Eliasmith, Chris

# Natural Language Processing
**2020**, Contextual Embeddings: When Are They Worth It? [[paper](https://arxiv.org/abs/2005.09117)]
* Simran Arora, Avner May, Jian Zhang, Christopher Ré, 	arXiv:2005.09117 [cs.CL]

**2020**, Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer, [[paper](https://arxiv.org/abs/1910.10683)]
* Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu, 	arXiv:1910.10683 [cs.LG]

**2019**, Unsupervised word embeddings capture latent knowledge from materials science literature, [[paper](https://www.nature.com/articles/s41586-019-1335-8)]
* Vahe Tshitoyan, John Dagdelen, Leigh Weston, Alexander Dunn, Ziqin Rong, Olga Kononova, Kristin A. Persson, Gerbrand Ceder & Anubhav Jain , Nature volume 571, pages95–98(2019)

**2019**, BioBERT: a pre-trained biomedical language representation model for biomedical text mining, 
* Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang, arXiv:1901.08746 [cs.CL]

**2019**, Patent Analytics Based on Feature Vector Space Model: A Case of IoT, [[paper](https://arxiv.org/abs/1904.08100)]
* Lei Lei, Jiaju Qi, Kan Zheng, arXiv:1904.08100 [cs.CL]

**2019**, RoBERTa: A Robustly Optimized BERT Pretraining Approach [[paper](https://arxiv.org/abs/1907.11692)] [[code](https://github.com/pytorch/fairseq/tree/master/examples/roberta)]
* Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692 [cs.CL]

**2019**, XLNet: Generalized Autoregressive Pretraining for Language Understanding [[paper](https://arxiv.org/abs/1906.08237)] [[code](https://github.com/zihangdai/xlnet)] [[keras-implementation](https://github.com/CyberZHG/keras-xlnet)]
* Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V. Le, 	arXiv:1906.08237 [cs.CL]

**2018**, Universal Language Model Fine-tuning for Text Classification [[paper](https://arxiv.org/abs/1801.06146)] [[implementations](https://paperswithcode.com/paper/universal-language-model-fine-tuning-for-text)]
* Jeremy Howard, Sebastian Ruder, arXiv:1801.06146 [cs.CL]

**2017**, Attention is all you need [[paper](https://arxiv.org/abs/1706.03762)] [[code](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py)] [[tutorial](https://www.tensorflow.org/beta/tutorials/text/transformer)]
* Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin, 	arXiv:1706.03762 [cs.CL]

**2016**, Enriching Word Vectors with Subword Information [[paper](https://arxiv.org/abs/1607.04606#)]
* Piotr Bojanowski, Edouard Grave, Armand Joulin, Tomas Mikolov, 	arXiv:1607.04606 [cs.CL]

# Biological Representation Learning
**2020**, Geodesics in fibered latent spaces: A geometric approach to learning correspondences between conditions, [[paper](https://arxiv.org/abs/2005.07852)]
* Tariq Daouda, Reda Chhaibi, Prudencio Tossou, Alexandra-Chloé Villani, 	arXiv:2005.07852 [stat.ML]

**2020**, High Accuracy Protein Structure Prediction Using Deep Learning [[paper](https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf)] [[announcement](https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology)]
John Jumper et al., Fourteenth Critical Assessment of Techniques for Protein Structure Prediction

**2019**, Improved protein structure prediction using potentials from deep learning, [[paper](https://www.nature.com/articles/s41586-019-1923-7)]
* Andrew W. Senior et al., Nature volume 577, pages706–710(2020)

**2019**, Probabilistic variable-length segmentation of protein sequences for discriminative motif discovery (DiMotif) and sequence embedding (ProtVecX) [[paper](https://www.nature.com/articles/s41598-019-38746-w)]
* Ehsaneddin Asgari, Alice C. McHardy & Mohammad R. K. Mofrad, Scientific Reportsvolume 9, Article number: 3577 (2019)

**2019**, Universal Deep Sequence Models for Protein Classification [[paper](https://www.biorxiv.org/content/10.1101/704874v1)]
* Nils Strodthoff, Patrick Wagner, Markus Wenzel, Wojciech Samek, doi: https://doi.org/10.1101/704874

**2019**, Unified rational protein engineering with sequence-only deep representation learning, [[paper](https://www.biorxiv.org/content/10.1101/589333v1)]
* Ethan C. Alley, Grigory Khimulya,  Surojit Biswas, Mohammed AlQuraishi, George M. Church, doi: https://doi.org/10.1101/589333

# Time Series Forecasting
**2018**, SeriesNet:A Generative Time Series Forecasting Model, [[paper](https://ieeexplore.ieee.org/document/8489522)]
* Zhipeng Shen ; Yuanming Zhang ; Jiawei Lu ; Jun Xu ; Gang Xiao, ISBN: 978-1-5090-6014-6

**2017**, Conditional Time Series Forecasting with Convolutional Neural Networks [[paper](https://arxiv.org/abs/1703.04691)]
* Anastasia Borovykh, Sander Bohte, Cornelis W. Oosterlee, arXiv:1703.04691 [stat.ML]

# Drug Design
**2020**, TrimNet: learning molecular representation from triplet messages for biomedicine [[paper](https://academic.oup.com/bib/advance-article-abstract/doi/10.1093/bib/bbaa266/5955940?redirectedFrom=fulltext)]
* Pengyong Li, Yuquan Li, Chang-Yu Hsieh, Shengyu Zhang, Xianggen Liu, Huanxiang Liu, Sen Song, Xiaojun Yao,  https://doi.org/10.1093/bib/bbaa266

**2020**, Molecular Design in Synthetically Accessible Chemical Space via Deep Reinforcement Learning [[paper](https://arxiv.org/abs/2004.14308)]
* Julien Horwood, Emmanuel Noutahi, arXiv:2004.14308 [physics.chem-ph]

**2020**, Principal Neighbourhood Aggregation for Graph Nets, [[paper](https://arxiv.org/abs/2004.05718)] [[code](https://github.com/lukecavabarrett/pna)]
* Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Liò, Petar Veličković, arXiv:2004.05718 [cs.LG]

**2020**, Towards Interpretable Sparse Graph Representation Learning with Laplacian Pooling, [[paper](https://arxiv.org/abs/1905.11577)] [[code](https://github.com/jdavid04/lapool)]
* Emmanuel Noutahi, Dominique Beaini, Julien Horwood, Sébastien Giguère, Prudencio Tossou, arXiv:1905.11577 [cs.LG]

**2020**, Molecular representation learning with language models and domain-relevant auxiliary tasks
* Benedek Fabian, Thomas Edlich, Héléna Gaspar, Marwin Segler, Joshua Meyers, Marco Fiscato, Mohamed Ahmed, arXiv:2011.13230 [cs.LG]

**2020**, Domain Extrapolation via Regret Minimization [[paper](https://arxiv.org/abs/2006.03908)]
* Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:2006.03908 [cs.LG]

**2019**, Exploring Chemical Compound Space with Quantum-Based Machine Learning, [[paper](https://arxiv.org/abs/1911.10084)]
* O. Anatole von Lilienfeld, Klaus-Robert Müller, Alexandre Tkatchenko, arXiv:1911.10084 [physics.chem-ph]

**2019**, Modeling Physico-Chemical ADMET Endpoints with Multitask Graph Convolutional Networks, [[paper](https://pubmed.ncbi.nlm.nih.gov/31877719/)]
* Floriane Montanari, Lara Kuhnke, Antonius Ter Laak, Djork-Arné Clevert, Molecules. 2019 Dec 21;25(1):44. doi: 10.3390/molecules25010044.

**2019**, Adaptive Deep Kernel Learning, [[paper](https://arxiv.org/abs/1905.12131)]
* Prudencio Tossou, Basile Dura, Francois Laviolette, Mario Marchand, Alexandre Lacoste, arXiv:1905.12131 [cs.LG]

**2019**, Efficient multi-objective molecular optimization in a continuous latent space, [[paper](https://pubs.rsc.org/en/content/articlelanding/2019/sc/c9sc01928f#!divAbstract)] [[code](https://github.com/jrwnter/mso)]
* Robin Winter, Floriane Montanari, OAndreas Steffen, Hans Briem, Frank Noé and  Djork-Arné Clevert, 

**2019**, Multi-Objective De Novo Drug Design with Conditional Graph Generative Model, [[paper](https://arxiv.org/abs/1801.07299)]
* Yibo Li, Liangren Zhang, Zhenming Liu, arXiv:1801.07299 [q-bio.QM]

**2019**, PharML.Bind: Pharmacologic Machine Learning for Protein-Ligand Interactions, [[paper](https://arxiv.org/abs/1911.06105)] [[code](https://github.com/jbalma/pharml)]
* Aaron D. Vose, Jacob Balma, Damon Farnsworth, Kaylie Anderson, Yuri K. Peterson, 	arXiv:1911.06105 [q-bio.BM]

**2019**, Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models, [[paper](https://arxiv.org/abs/2004.01215)]
* Vijil Chenthamarakshan, Payel Das, Inkit Padhi, Hendrik Strobelt, Kar Wai Lim, Ben Hoover, Samuel C. Hoffman, Aleksandra Mojsilovic, 	arXiv:2004.01215 [cs.LG]

**2019**, A Deep Learning Approach to Antibiotic Discovery [[paper](https://www.cell.com/action/showPdf?pii=S0092-8674%2820%2930102-1)]
* Jonathan M. Stokes, Kevin Yang, Kyle Swanson, ..., Tommi S. Jaakkola, Regina Barzilay, James J. Collins, Cell 180, 688–702, February 20, 2020

**2019**, Composing Molecules with Multiple Property Constraints, [[paper](https://arxiv.org/abs/2002.03244)]
* Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:2002.03244 [cs.LG]

**2019**, GraphLIME: Local Interpretable Model Explanations for Graph Neural Networks, [[paper](https://arxiv.org/abs/2001.06216)]
* Qiang Huang, Makoto Yamada, Yuan Tian, Dinesh Singh, Dawei Yin, Yi Chang, arXiv:2001.06216 [cs.LG]

**2019**, Evaluating Scalable Uncertainty Estimation Methods for DNN-Based Molecular Property Prediction [[paper](https://arxiv.org/abs/1910.03127)]
* Gabriele Scalia, Colin A. Grambow, Barbara Pernici, Yi-Pei Li, William H. Green, arXiv:1910.03127 [cs.LG]

**2019**, Rethinking drug design in the artificial intelligence era [[paper](https://www.nature.com/articles/s41573-019-0050-3)]
* Schneider P., Walters W., Plowright A., Sieroka N., Listgarten J., Goodnow R., Fisher J., Jansen J., Duca J., Rush T., Zentgraf M., Hill J., Krutoholow E., Kohler M., Blaney J., Funatsu K., Luebkemann C., Schneider G., Nat Rev Drug Discov (2019)

**2019**, Machine Learning for Scent: Learning Generalizable Perceptual Representations of Small Molecules [[paper](https://arxiv.org/abs/1910.10685)]
* Benjamin Sanchez-Lengeling, Jennifer N. Wei, Brian K. Lee, Richard C. Gerkin, Alán Aspuru-Guzik, Alexander B. Wiltschko, 	arXiv:1910.10685 [stat.ML]

**2019**, Deep learning enables rapid identification of potent DDR1 kinase inhibitors [[paper](https://www.nature.com/articles/s41587-019-0224-x)]
* Alex Zhavoronkov et al., Nature Biotechnologyvolume 37, pages1038–1040 (2019)

**2019**, Deep learning for molecular design - a review of the state of the art [[paper](https://arxiv.org/abs/1903.04388)]
* Daniel C. Elton, Zois Boukouvalas, Mark D. Fuge, Peter W. Chung, 	arXiv:1903.04388 [cs.LG]

**2018**, Junction Tree Variational Autoencoder for Molecular Graph Generation [[paper](https://arxiv.org/abs/1802.04364)]
* Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:1802.04364 [cs.LG]

**2017**, Neural Message Passing for Quantum Chemistry, [[paper](https://arxiv.org/abs/1704.01212)] [[code](https://github.com/priba/nmp_qc)]
* Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, George E. Dahl, arXiv:1704.01212 [cs.LG]

# Interpretation / Explainability
**TabNet**, TabNet: Attentive Interpretable Tabular Learning, [[paper](https://arxiv.org/abs/1908.07442)]
* Sercan O. Arik, Tomas Pfister, arXiv:1908.07442 [cs.LG]

**2020**, Clinically applicable deep learning for diagnosis and referral in retinal disease, [[paper](https://www.nature.com/articles/s41591-018-0107-6)]
* Jeffrey De Fauw, Joseph R. Ledsam, Olaf Ronneberger, Nature Medicine volume 24, pages1342–1350(2018)

**2019**, GNNExplainer: Generating Explanations for Graph Neural Networks [[paper](https://arxiv.org/abs/1903.03894)] [[code](https://github.com/RexYing/gnn-model-explainer)]
* Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, Jure Leskovec, 	arXiv:1903.03894 [cs.LG]

**2019**, Functional Transparency for Structured Data: a Game-Theoretic Approach, [[paper](https://arxiv.org/abs/1902.09737)]
* Guang-He Lee, Wengong Jin, David Alvarez-Melis, Tommi S. Jaakkola, 	arXiv:1902.09737 [cs.LG]

**2019**, Using attribution to decode binding mechanism in neural network models for chemistry, [[paper](https://www.pnas.org/content/116/24/11624)]
* Kevin McCloskey, Ankur Taly, Federico Monti, Michael P. Brenner, and Lucy J. Colwell, PNAS June 11, 2019 116 (24) 11624-11629

**2019**, Interpretable Deep Learning in Drug Discovery, [[paper](https://arxiv.org/abs/1903.02788)] [[code](https://github.com/bioinf-jku/interpretable_ml_drug_discovery)]
* Kristina Preuer, Günter Klambauer, Friedrich Rippmann, Sepp Hochreiter, Thomas Unterthiner, arXiv:1903.02788 [cs.LG]

**2019**, Can You Trust This Prediction? Auditing Pointwise Reliability After Learning [[paper](https://arxiv.org/abs/1901.00403)]
* Peter Schulam, Suchi Saria, arXiv:1901.00403 [stat.ML]

**2018**, BayesGrad: Explaining Predictions of Graph Convolutional Networks, [[paper](https://arxiv.org/abs/1807.01985)] [[code](https://github.com/pfnet-research/bayesgrad)]
* Hirotaka Akita, Kosuke Nakago, Tomoki Komatsu, Yohei Sugawara, Shin-ichi Maeda, Yukino Baba, Hisashi Kashima, 	arXiv:1807.01985 [cs.LG]

**2017**, A Unified Approach to Interpreting Model Predictions [[paper](https://arxiv.org/abs/1705.07874)]
* Scott Lundberg, Su-In Lee, arXiv:1705.07874 [cs.AI]

# Chemistry
**2019**, Ab-Initio Solution of the Many-Electron Schrödinger Equation with Deep Neural Networks [[paper](https://arxiv.org/abs/1909.02487)]
* David Pfau, James S. Spencer, Alexander G. de G. Matthews, W. M. C. Foulkes, arXiv:1909.02487 [physics.chem-ph]

**2020**, Review and Prospect: Deep Learning in Nuclear Magnetic Resonance Spectroscopy [[paper](https://arxiv.org/abs/2001.04813)]
* Dicheng Chen, Zi Wang, Di Guo, Vladislav Orekhov, Xiaobo Qu, arXiv:2001.04813 [physics.med-ph]

# Non-technical
**2020**, The upside of being a digital pharma player, [[paper](https://www.sciencedirect.com/science/article/pii/S1359644620302270)]
* Alexander Schuhmacher, Alexander Gatto, Markus Hinder, Michael Kuss, Oliver Gassmann

**2020**, The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence, [[paper](https://arxiv.org/abs/2002.06177)]
* Gary Marcus, 	arXiv:2002.06177 [cs.AI]

**2019**, 150 successful Machine Learning models: 6 lessons learned at Booking.com, [[paper](https://www.kdd.org/kdd2019/accepted-papers/view/150-successful-machine-learning-models-6-lessons-learned-at-booking.com)]
* Pablo Estevez, Themistoklis Mavridis and Lucas Bernardi

**2018**, The state-of-the-art on Intellectual Property Analytics (IPA): A literature review on artificial intelligence, machine learning and deep learning methods for analysing intellectual property (IP) data [[paper](https://reader.elsevier.com/reader/sd/pii/S0172219018300103?token=FA15B51A34BCC633A61D1925EEC1F5922254EBB8BD769D2AAFC3596735FFA3AFA528673C2CD6FA80B238773C670A6348)]
* Aristodemou, L. and Tietze, F.

# Causality
**2020**, Algorithms for Causal Reasoning in Probability Trees, [[paper](https://arxiv.org/abs/2010.12237)] [[colab](https://colab.research.google.com/github/deepmind/deepmind_research/blob/master/causal_reasoning/Causal_Reasoning_in_Probability_Trees.ipynb#scrollTo=ZB-JZdum16ZJ)]
* Tim Genewein, Tom McGrath, Grégoire Déletang, Vladimir Mikulik, Miljan Martic, Shane Legg, Pedro A. Ortega, arXiv:2010.12237 [cs.AI]

**2018**, Causal Discovery with Attention-Based Convolutional Neural Networks, [[paper](https://www.mdpi.com/2504-4990/1/1/19)]
* Meike Nauta,Doina Bucur and Christin Seifert, Mach. Learn. Knowl. Extr. 2019, 1(1), 312-340

# Clinical Trials
**2019**, A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis [[paper](https://www.sciencedirect.com/science/article/pii/S2589750019301232)]
* Liu et al., The Lancet Digital Health, Volume 1, Issue 6, October 2019, Pages e271-e297

**2019**, Machine Learning with Statistical Imputation for Predicting Drug Approvals [[paper](https://hdsr.mitpress.mit.edu/pub/ct67j043/release/9)]
* Andrew W. Lo, Kien Wei Siah, and Chi Heem Wong, Machine Learning with Statistical Imputation for Predicting Drug Approvals. Harvard Data Science Review, 1(1)

**2019**, Artificial Intelligence for Clinical Trial Design, [[paper](https://www.sciencedirect.com/science/article/pii/S0165614719301300)]
* Herrer et al., Trends in Pharmacological Sciences, Volume 40, Issue 8, August 2019, Pages 577-591

**2019**, Estimating Site Performance (ESP): can trial managers predict recruitment success at trial sites? An exploratory study, [[paper](https://trialsjournal.biomedcentral.com/articles/10.1186/s13063-019-3287-6)]
* Hanne Bruhn, Shaun Treweek, Anne Duncan, Kirsty Shearer, Sarah Cameron, Karen Campbell, Karen Innes, Dawn McRae & Seonaidh C. Cotton, Trials volume 20, Article number: 192 (2019)

**2018**, Quantifying and visualizing site performance in clinical trials, [[paper](https://www.sciencedirect.com/science/article/pii/S2451865417301825)]
* Eric Yang, Christopher O'Donovan, JodiLyn Phillips, Leone Atkinson, Krishnendu Ghosh, Dimitris K.Agrafiotis, Contemporary Clinical Trials Communications
Volume 9, March 2018, Pages 108-114

**2017**, Predicting enrollment performance of investigational centers in phase III multi-center clinical trials, 
* Rutger M.van den Borab, Diederick E.Grobbeeab, Bas J.Oostermana, Petrus W.J.Vaessena, Kit C.B.Roesb, Contemporary Clinical Trials Communications
Volume 7, September 2017, Pages 208-216

**2011**, Performance-Based Site Selection Reduces Costs and Shortens Enrollment Time [[paper](https://www.phesi.com/wp-content/uploads/2020/02/Gen-The-Monitor-2011.pdf)]
* Gen Li, PhD, MBA | Robert Gray, MBA

# Reinforcement Learning
**2020**, Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, [[paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3690996)] [[code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020)] [[medium](https://towardsdatascience.com/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02)]
* Hongyang Yang et al. ICAIF-2020

**2020**, CURL: Contrastive Unsupervised Representations for Reinforcement Learning, [[paper](https://arxiv.org/abs/2004.04136)] [[code](https://github.com/MishaLaskin/curl)]
* Aravind Srinivas, Michael Laskin, Pieter Abbeel, arXiv:2004.04136 [cs.LG]

**2017**, Rainbow: Combining Improvements in Deep Reinforcement Learning, [[paper](https://arxiv.org/abs/1710.02298)]
* Matteo Hessel, Joseph Modayil, Hado van Hasselt, Tom Schaul, Georg Ostrovski, Will Dabney, Dan Horgan, Bilal Piot, Mohammad Azar, David Silver, arXiv:1710.02298 [cs.AI]

**1998**, Reinforcement Learning for Trading, [[paper](https://papers.nips.cc/paper/1998/file/4e6cd95227cb0c280e99a195be5f6615-Paper.pdf)]
John Moody and Matthew Saffell, Advances in Neural Information Processing Systems 11 (NIPS 1998)

# Evolutionary Psycology
**2020**, The Policy Relevance of Personality Traits, [[paper](https://psyarxiv.com/a9rbn/)]
Wiebke BleidornPatrick HillMitja BackJaap DenissenMarie HenneckeChris HopwoodMarkus JokelaChristian KandlerRichard E. LucasMaike LuhmannUlrich OrthJenny WagnerCornelia WrzusJohannes ZimmermannBrent Roberts, Inpress: American Psychologist
